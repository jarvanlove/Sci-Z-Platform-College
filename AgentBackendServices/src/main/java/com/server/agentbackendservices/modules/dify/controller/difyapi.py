#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dify æ–‡ä»¶ä¸Šä¼  - æœ€ç»ˆç‰ˆæœ¬
é…ç½®ï¼štext-embedding-v3 + gte-rerank + æ··åˆæ£€ç´¢ + é«˜è´¨é‡ç´¢å¼• + é€šç”¨åˆ†æ®µ
"""

import requests
import json
import os
import sys

# # ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
# if sys.platform == 'win32':
#     import io
#     sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
#     sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ========================================
# ğŸ”§ åŸºæœ¬é…ç½®
# ========================================
# ğŸ”¥ äº‘ç«¯æµ‹è¯•ï¼ˆå»æ‰ /v1ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨æ·»åŠ ï¼‰
BASE_URL = "http://192.168.1.203"  # âš ï¸ ä¸è¦åŠ  /v1
DATASET_ID = "fdfa778d-3d6c-430f-9c55-69234da7994c"
API_KEY = "dataset-XfEGbHDJ9C3koNrbyN0sYcrl"

# æœ¬åœ°æµ‹è¯•ï¼ˆåˆ‡æ¢æ—¶å–æ¶ˆæ³¨é‡Šï¼‰
# BASE_URL = "http://localhost:5001"
# DATASET_ID = "00472067-44cf-4af7-ba3a-cd2d6cb39239"
# API_KEY = "dataset-AYHOkSjR0iajmQdjYCJH0dkF"
# ========================================
# ğŸ“ æ–‡ä»¶é…ç½®
# ========================================
# ğŸ”¥ é€‰æ‹©ä¸Šä¼ æ–¹å¼ï¼ˆäºŒé€‰ä¸€ï¼‰

# æ–¹å¼1: ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼ˆæ¨èï¼‰
USE_LOCAL_FILE = True
LOCAL_FILE_PATH = r"D:\Workæ–‡æ¡£\å·¥ä¸šäº’è”ç½‘å¹³å°è½¯ä»¶éƒ¨ç½²æ•™ç¨‹.docx"

# æ–¹å¼2: ä½¿ç”¨æµ‹è¯•æ–‡æœ¬
# USE_LOCAL_FILE = False  # å–æ¶ˆæ³¨é‡Šè¿™è¡Œæ¥ä½¿ç”¨æµ‹è¯•æ–‡æœ¬

# ========================================
# ğŸ¯ æ¨¡å‹é…ç½®
# ========================================
# æ ¹æ®æ‚¨çš„è¦æ±‚é…ç½®

UPLOAD_CONFIG = {
    # ç´¢å¼•æ–¹å¼ï¼šé«˜è´¨é‡
    "indexing_technique": "high_quality",
    
    # ç´¢å¼•å†…å®¹å½¢å¼ï¼šæ–‡æœ¬æ¨¡å¼
    "doc_form": "text_model",
    
    # æ–‡æ¡£è¯­è¨€
    "doc_language": "Chinese",
    
    # ========== Embedding æ¨¡å‹é…ç½® ==========
    # ğŸ”¥ é‡è¦ï¼šæ ¹æ®æ‚¨ Dify ä¸­å®é™…é…ç½®çš„æ¨¡å‹ä¿®æ”¹
    "embedding_model": "text-embedding-v3",
    "embedding_model_provider": "tongyi",  # é€šä¹‰åƒé—®
    
    # ========== æ£€ç´¢æ¨¡å‹é…ç½® ==========
    "retrieval_model": {
        # æ··åˆæ£€ç´¢
        "search_method": "hybrid_search",
        
        # ğŸ”¥ æš‚æ—¶ç¦ç”¨ rerankï¼ˆå¦‚æœæ‚¨æ²¡æœ‰é…ç½® rerank æ¨¡å‹ï¼‰
        # å¦‚æœéœ€è¦å¯ç”¨ï¼Œè¯·å…ˆåœ¨ Dify æ§åˆ¶å°é…ç½® rerank æ¨¡å‹
        "reranking_enable": False,
        
        # å¦‚æœæ‚¨å·²é…ç½® rerankï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶ä¿®æ”¹ provider
        "reranking_enable": True,
        "reranking_model": {
            # å¸¸è§çš„ rerank providers:
            # - "xinference" (æœ¬åœ°éƒ¨ç½²çš„ gte-rerank)
            # - "jina" (Jina AI rerank)
            # - "cohere" (Cohere rerank)
            # - "voyage" (Voyage AI)
            "reranking_provider_name": "langgenius/tongyi/tongyi",  # ä¿®æ”¹ä¸ºæ‚¨å®é™…çš„ provider
            "reranking_model_name": "gte-rerank"
        },
        
        # å¬å›æ•°é‡
        "top_k": 3,
        
        # åˆ†æ•°é˜ˆå€¼
        "score_threshold_enabled": False,
        "score_threshold": 0.5
    },
    
    # ========== å¤„ç†è§„åˆ™ï¼šé€šç”¨åˆ†æ®µï¼ˆè‡ªåŠ¨æ¨¡å¼ï¼‰==========
    "process_rule": {
        "mode": "automatic"
    }
}

# ========================================
# ğŸ“ å¯é€‰ï¼šå¦‚æœæ‚¨çš„çŸ¥è¯†åº“å·²ç»é…ç½®å¥½ï¼Œå¯ä»¥ä½¿ç”¨ç®€åŒ–é…ç½®
# ========================================
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼Œä½¿ç”¨çŸ¥è¯†åº“é»˜è®¤é…ç½®
# UPLOAD_CONFIG = {
#     "process_rule": {
#         "mode": "automatic"
#     }
# }


def upload_file():
    """ä¸Šä¼ æ–‡ä»¶åˆ° Dify"""
    
    print("=" * 60)
    print("ğŸ“¤ Dify æ–‡ä»¶ä¸Šä¼ å·¥å…·")
    print("=" * 60)
    print(f"ğŸŒ æœåŠ¡å™¨: {BASE_URL}")
    print(f"ğŸ“¦ æ•°æ®é›†: {DATASET_ID}")
    print()
    
    # å‡†å¤‡æ–‡ä»¶
    if USE_LOCAL_FILE:
        if not os.path.exists(LOCAL_FILE_PATH):
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {LOCAL_FILE_PATH}")
            return
        
        print(f"ğŸ“ æœ¬åœ°æ–‡ä»¶: {LOCAL_FILE_PATH}")
        file_size = os.path.getsize(LOCAL_FILE_PATH) / 1024
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
        
        with open(LOCAL_FILE_PATH, 'rb') as f:
            content = f.read()
        
        filename = os.path.basename(LOCAL_FILE_PATH)
        
        # ç¡®å®š MIME ç±»å‹
        ext = os.path.splitext(filename)[1].lower()
        mime_types = {
            '.txt': 'text/plain',
            '.pdf': 'application/pdf',
            '.doc': 'application/msword',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.md': 'text/markdown',
        }
        mime_type = mime_types.get(ext, 'application/octet-stream')
        
        files = {'file': (filename, content, mime_type)}

    
    # å‡†å¤‡è¯·æ±‚
    url = f"{BASE_URL}/v1/datasets/{DATASET_ID}/document/create-by-file"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    data = {'data': json.dumps(UPLOAD_CONFIG)}
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("\nğŸ“‹ ä¸Šä¼ é…ç½®:")
    print(json.dumps(UPLOAD_CONFIG, indent=2, ensure_ascii=False))
    print()
    
    # å‘é€è¯·æ±‚
    print("ğŸš€ æ­£åœ¨ä¸Šä¼ ...")
    try:
        response = requests.post(url, headers=headers, files=files, data=data, timeout=300)
        
        print(f"\nğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            print("âœ… ä¸Šä¼ æˆåŠŸ!")
            result = response.json()
            
            if 'document' in result:
                doc = result['document']
                print("\n" + "=" * 60)
                print("ğŸ“„ æ–‡æ¡£ä¿¡æ¯:")
                print(f"  - ID: {doc.get('id')}")
                print(f"  - åç§°: {doc.get('name')}")
                print(f"  - çŠ¶æ€: {doc.get('indexing_status')}")
                print(f"  - æ‰¹æ¬¡: {result.get('batch')}")
                print("=" * 60)
                
                # æä¾›æŸ¥è¯¢ç´¢å¼•çŠ¶æ€çš„å‘½ä»¤
                print("\nğŸ’¡ æŸ¥è¯¢ç´¢å¼•çŠ¶æ€:")
                print(f"curl -X GET \"{BASE_URL}/v1/datasets/{DATASET_ID}/documents/{result.get('batch')}/indexing-status\" \\")
                print(f"  -H \"Authorization: Bearer {API_KEY}\"")
            
            print("\nå®Œæ•´å“åº”:")
            print(json.dumps(result, indent=2, ensure_ascii=False))
            
        elif response.status_code == 400:
            print("âŒ ä¸Šä¼ å¤±è´¥: è¯·æ±‚å‚æ•°é”™è¯¯")
            error_info = response.json()
            print(json.dumps(error_info, indent=2, ensure_ascii=False))
            
            # æ ¹æ®é”™è¯¯æä¾›å»ºè®®
            if error_info.get('code') == 'provider_not_initialize':
                print("\nğŸ’¡ è§£å†³å»ºè®®:")
                print("1. æ£€æŸ¥ Dify æ§åˆ¶å° â†’ è®¾ç½® â†’ æ¨¡å‹ä¾›åº”å•†")
                print("2. ç¡®ä¿å·²é…ç½®å¯¹åº”çš„ Embedding æ¨¡å‹")
                print("3. ä¿®æ”¹æœ¬è„šæœ¬ä¸­çš„ embedding_model_provider")
                print("   å½“å‰é…ç½®: " + UPLOAD_CONFIG.get('embedding_model_provider', 'N/A'))
                print("\nå¸¸è§ Provider åç§°:")
                print("  - OpenAI: 'openai'")
                print("  - Azure OpenAI: 'azure_openai'")
                print("  - æ™ºè°± AI: 'zhipuai'")
                print("  - é€šä¹‰åƒé—®: 'tongyi'")
                print("  - Ollama: 'ollama'")
        else:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: HTTP {response.status_code}")
            print(response.text)
        
    except requests.exceptions.RequestException as e:
        print(f"\nâŒ è¯·æ±‚å¼‚å¸¸: {e}")
        if hasattr(e, 'response') and e.response is not None:
            print(f"å“åº”å†…å®¹: {e.response.text}")
    except Exception as e:
        print(f"\nâŒ æœªçŸ¥é”™è¯¯: {e}")
    
    print()


if __name__ == "__main__":
    upload_file()

